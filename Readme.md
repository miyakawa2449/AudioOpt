# AudioOpt - 音声クローニングシステム

PyTorchとTorchaudioを使用したエンドツーエンドの音声クローニング・音声合成システムです。

## 🎯 概要

AudioOptは、少量の音声データから音声クローニングを行うことができるPythonベースのディープラーニングシステムです。テキストから音声を合成し、特定の話者の声質を再現することを目指しています。

## ✨ 特徴

- **エンドツーエンドの音声合成**: テキストから直接音声を生成
- **音声前処理**: ノイズ除去、無音部分除去、正規化
- **データ拡張**: 速度変更、ピッチ変更による学習データの拡張
- **複数の音声合成手法**: 確実シンプルボコーダー、五十音対応ボコーダー、ニューラルボコーダー
- **日本語音韻対応**: 五十音表に基づいた音韻特徴ボコーダー
- **対話式インターフェース**: メニュー形式での簡単操作
- **充実した診断機能**: モデル・音声品質の詳細診断
- **GPU対応**: CUDAによる高速学習・推論
- **モジュラー設計**: 各コンポーネントが独立して動作

## 🛠️ システム要件

### 必須環境
- Python 3.8+
- CUDA対応GPU（推奨）
- 4GB以上のRAM

### 依存関係
```bash
torch>=1.12.0
torchaudio>=0.12.0
numpy>=1.20.0
soundfile>=0.10.0
matplotlib>=3.5.0
scipy>=1.9.0
```

## 📦 インストール

### 1. リポジトリのクローン
```bash
git clone https://github.com/miyakawa2449/AudioOpt.git
cd AudioOpt
```

### 2. Conda環境の作成
```bash
conda create -n voice-clone python=3.10
conda activate voice-clone
```

### 3. 依存関係のインストール
```bash
# PyTorchとTorchaudio（CUDA対応）
conda install pytorch torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia

# その他の依存関係
conda install numpy matplotlib soundfile scipy -c conda-forge
```

## 📁 プロジェクト構造
```
AudioOpt/
├── src/
│   ├── audio/
│   │   └── preprocessor.py      # 音声前処理
│   ├── text/
│   │   └── text_processor.py    # テキスト処理
│   ├── model/
│   │   ├── dataset.py           # データセット処理
│   │   └── voice_clone_model.py # 音声クローニングモデル
│   └── core/
│       └── voice_cloner.py      # メインシステム（全面再設計済み）
├── dataset/
│   ├── audio_files/             # 音声ファイル (.wav)
│   ├── meta_files/              # テキストファイル (.txt)
│   ├── processed/               # 前処理済みデータ
│   └── phoneme_data/            # 五十音台本データ（将来対応）
├── models/                      # 訓練済みモデル
├── output/                      # 合成音声出力
├── Reports/                     # 開発ログ・作業記録
│   ├── 2025-06-12.md           # 音声長問題解決
│   └── 2025-06-13.md           # 音声品質改善・五十音対応
├── main.py                      # メインプログラム
└── README.md
```

## 🚀 使用方法

### 1. データの準備
音声ファイルとテキストファイルを対応する形で配置：
```
dataset/audio_files/audio_1.wav
dataset/audio_files/audio_2.wav
...

dataset/meta_files/meta_1.txt
dataset/meta_files/meta_2.txt
...
```
**重要**: ファイル名は `audio_N.wav` と `meta_N.txt` の形式で、同じ番号Nを使用してください。

### 2. システムの起動
```bash
python main.py
```

### 3. メニュー構成
```
=== メニュー ===
1. データセットの前処理とモデル訓練
2. 既存モデルの読み込み
3. 音声合成
4. 新しいデータの追加
5. データファイル確認
6. システム情報表示
7. 前処理結果確認
8. モデル・音声合成診断
9. テスト音声生成
10. 詳細モデル診断
11. 改善パラメータで再訓練
12. ボコーダー問題診断
13. 緊急モデル修正
14. 外部ボコーダー使用設定
0. 終了
```

### 4. 基本的な使用フロー
1. **データセットの確認** (メニュー 5)
2. **モデルの訓練** (メニュー 1)
3. **モデル診断** (メニュー 8)
4. **音声合成** (メニュー 3)

## 🎵 音声合成の例
```python
# プログラム内での使用例
from src.core import VoiceCloner

cloner = VoiceCloner()
cloner.load_model("models/voice_clone_model.pth")
cloner.synthesize_speech("こんにちは、世界！", "output/hello_world.wav")
```

## ⚙️ 設定とカスタマイズ

### 学習パラメータ
- **エポック数**: 50-200 (データ量による)
- **バッチサイズ**: 1-4 (GPU メモリによる)
- **学習率**: 0.0001-0.001

### 音声パラメータ
- **サンプルレート**: 22050 Hz
- **メルスペクトログラム**: 80 bins
- **STFT設定**: n_fft=2048, hop_length=256
- **メル正規化範囲**: [-4.000, 4.000]

## 🔧 高度な機能

### 五十音対応ボコーダー
```python
# 日本語音韻特徴に対応した音声合成
audio = cloner._japanese_phoneme_vocoder(mel_spec)
```

### 確実動作ボコーダー
```python
# 安定性重視のシンプルボコーダー
audio = cloner._reliable_vocoder(mel_spec)
```

### メル正規化制御
```python
# 完璧なメルスペクトログラム正規化
mel_normalized = cloner._normalize_mel_spectrogram(mel_outputs)
```

### 診断機能
```python
# 詳細モデル診断
cloner.detailed_model_diagnosis()

# ボコーダー問題診断
cloner.diagnose_vocoder_issue()
```

## 📊 パフォーマンス

### 推奨データ量
- **最低**: 17+ サンプル (基本動作確認)
- **実用**: 100-500 サンプル
- **高品質**: 1000+ サンプル

### 学習時間（例）
- **100サンプル**: 約10-30分 (GPU)
- **500サンプル**: 約30-60分 (GPU)

### 音声品質
- **音声長**: 0.6-11.6秒の自然な長さ
- **サンプルレート**: 22050Hz
- **品質**: 砂嵐から認識可能な音声へ大幅改善
- **メル正規化**: [-4.000, 4.000]の完璧な範囲制御

## 🐛 トラブルシューティング

### よくある問題

#### 1. ライブラリインポートエラー
```bash
# 依存関係の再確認
python -c "import torch, torchaudio, soundfile, scipy; print('All dependencies OK')"
```

#### 2. CUDA関連エラー
```bash
# CPU版での実行
export CUDA_VISIBLE_DEVICES=""
python main.py
```

#### 3. 音声ファイル読み込みエラー
- ファイル形式がWAVであることを確認
- ファイル名が正しい命名規則に従っていることを確認

#### 4. 合成音声が短すぎる
- **メニュー13**: 緊急モデル修正を実行
- 音声長制御機能が自動的に50フレーム以上に延長

#### 5. 合成音声がノイズのみ（砂嵐）
- **解決済み**: 確実動作ボコーダーにより改善
- **メニュー12**: ボコーダー問題診断を実行
- 自動的に最適なボコーダーを選択

#### 6. 日本語の発音が不自然
- **五十音対応ボコーダー**が自動適用
- 台本録音データがある場合は実測値ベースで改善

## 🔍 診断機能

### 詳細モデル診断 (メニュー10)
- データセット情報の確認
- モデル層別出力の分析
- メルスペクトログラム特性の評価

### ボコーダー診断 (メニュー12)
- 人工メルスペクトログラムテスト
- 実際のモデル出力との比較
- 音声品質の評価

### 緊急修正機能 (メニュー13)
- 短すぎる音声出力の強制延長
- モデルの出力制御修正
- 即座に使用可能な応急処置

## 📈 最新の改善点 (2025年6月13日)

### ✅ 解決済みの問題
- **音声品質**: 砂嵐 → 認識可能な「あー、あー、あー」音に大幅改善
- **メル正規化**: [-52, +33] → [-4.000, 4.000]の完璧な範囲制御
- **音声長問題**: 0.15秒 → 0.6-11.6秒の適切な長さに改善
- **モジュラー設計**: voice_cloner.pyの全面再設計完了

### 🆕 新機能
- **五十音対応ボコーダー**: 日本語音韻特徴に基づいた音声合成
- **確実動作ボコーダー**: 安定性重視のフォールバック機能
- **段階的ボコーダー選択**: 品質と安定性のバランス
- **台本録音データ統合準備**: phoneme_data フォルダ対応

### 🔄 現在改善中
- **音韻推定精度**: メルスペクトログラムからの音韻特徴抽出
- **フォルマント調整**: より自然な日本語音韻の実現
- **台本録音との統合**: 理論値から実測値ベースへの進化

## 🎌 日本語音韻対応

### 五十音表サポート
- **あ行**: あ、い、う、え、お (基本母音)
- **か行**: か、き、く、け、こ (破裂音特性)
- **さ行**: さ、し、す、せ、そ (摩擦音特性)
- **た行**: た、ち、つ、て、と (破裂音特性)
- **な行**: な、に、ぬ、ね、の (鼻音特性)
- **は行**: は、ひ、ふ、へ、ほ (気息音特性)
- **ま行**: ま、み、む、め、も (鼻音特性)
- **や行**: や、ゆ、よ (半母音特性)
- **ら行**: ら、り、る、れ、ろ (流音特性)
- **わ行**: わ、を (半母音特性)
- **ん**: 鼻音

### 音韻特徴
- **フォルマント周波数**: 各音韻の実測値ベース
- **基本周波数**: 日本語話者に適した80-400Hz範囲
- **音韻分類**: エネルギー分布による自動推定
- **特殊処理**: 破裂音、摩擦音、鼻音、気息音に対応

## 🛣️ 今後の計画
- [ ] 台本録音データとの完全統合
- [ ] 実測フォルマントデータベースの構築
- [ ] HiFi-GAN等の外部ボコーダー統合
- [ ] リアルタイム音声合成
- [ ] 多話者対応
- [ ] Web インターフェース
- [ ] 音声品質評価指標の追加

## 🤝 コントリビューション
1. このリポジトリをフォーク
2. 新しいブランチを作成 (`git checkout -b feature/amazing-feature`)
3. 変更をコミット (`git commit -m 'Add amazing feature'`)
4. ブランチにプッシュ (`git push origin feature/amazing-feature`)
5. プルリクエストを作成

## 📄 ライセンス
このプロジェクトはMITライセンスの下で公開されています。

## 🙏 謝辞
- PyTorchチーム
- Torchaudioチーム
- 音声処理コミュニティ

## 📞 お問い合わせ
**Email**: t.miyakawa244@gmail.com

⭐ このプロジェクトが役に立った場合は、スターを付けていただけると嬉しいです！

---

## 📋 技術詳細

### 1. アーキテクチャ

#### モデル構造
- **エンコーダ**: LSTM ベースのテキストエンコーダ
- **デコーダ**: Attention付きLSTMデコーダ
- **出力**: 80次元メルスペクトログラム

### 2. 音声合成パイプライン

1. **テキスト前処理** → 数値序列変換
2. **モデル推論** → メルスペクトログラム生成
3. **メル正規化** → [-4.000, 4.000]範囲に完璧正規化
4. **音声長制御** → 最小50フレーム保証
5. **ボコーダー選択** → 五十音対応 → 確実動作 → フォールバック
6. **音声波形生成** → 日本語音韻特徴反映
7. **後処理** → フィルタリング・正規化

### 3. ボコーダー技術

#### 五十音対応ボコーダー
- **音韻データベース**: 理論値ベースの五十音特徴
- **フォルマント合成**: 各音韻の特徴周波数
- **音韻推定**: メルスペクトログラムからの自動分類
- **特殊処理**: 破裂音、摩擦音、鼻音、気息音、流音、半母音

#### 確実動作ボコーダー
- **基本周波数**: 150Hz ベース（日本語話者平均）
- **調波構造**: 1-3次調波による自然音
- **エネルギー制御**: 適応的振幅調整
- **安定性重視**: シンプルで確実な動作

### 4. パフォーマンス最適化

#### GPU使用時
- **バッチサイズ**: 2～4 推奨
- **メモリ使用量**: 約2～4GB
- **学習速度**: 100エポックあたり約15～30分

#### CPU使用時
- **バッチサイズ**: 1 推奨
- **学習速度**: 100エポックあたり約1～2時間

### 5. データ前処理詳細

#### 音声前処理
- **サンプリングレート正規化**: 22050Hz
- **ノイズ除去**: スペクトル減算法
- **無音除去**: RMSベース検出
- **正規化**: RMS正規化

#### メルスペクトログラム正規化
- **クリッピング**: [-10, +10]で極端値除去
- **正規化**: [-4.000, 4.000]の完璧な範囲制御
- **異常値処理**: NaN/Inf の自動修正
- **品質保証**: 音声合成に最適な数値範囲

---

**最終更新**: 2025年6月13日