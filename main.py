"""
éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ  - ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚°ãƒ©ãƒ 
æ•´ç†ãƒ»å†æ§‹æˆç‰ˆ
"""

import sys
import os
import traceback

# srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

try:
    from src.core import VoiceCloner
except ImportError as e:
    print(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    print("ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š")
    print("1. srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã‹")
    print("2. å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒå…¨ã¦é…ç½®ã•ã‚Œã¦ã„ã‚‹ã‹")
    print("3. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹")
    sys.exit(1)

# =============================================================================
# ã‚·ã‚¹ãƒ†ãƒ é–¢é€£æ©Ÿèƒ½
# =============================================================================

def check_dependencies():
    """ä¾å­˜é–¢ä¿‚ã‚’ãƒã‚§ãƒƒã‚¯"""
    missing_packages = []
    
    try:
        import torch
        print(f"âœ“ PyTorch: {torch.__version__}")
    except ImportError:
        missing_packages.append("torch")
    
    try:
        import torchaudio
        print(f"âœ“ Torchaudio: {torchaudio.__version__}")
    except ImportError:
        missing_packages.append("torchaudio")
    
    try:
        import soundfile
        print(f"âœ“ Soundfile: {soundfile.__version__}")
    except ImportError:
        missing_packages.append("soundfile")
    
    try:
        import numpy
        print(f"âœ“ NumPy: {numpy.__version__}")
    except ImportError:
        missing_packages.append("numpy")
    
    if missing_packages:
        print(f"\nâŒ ä¸è¶³ã—ã¦ã„ã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸: {', '.join(missing_packages)}")
        print("ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ï¼š")
        print(f"conda install {' '.join(missing_packages)}")
        return False
    
    print("âœ“ å…¨ã¦ã®ä¾å­˜é–¢ä¿‚ãŒæº€ãŸã•ã‚Œã¦ã„ã¾ã™\n")
    return True

def display_system_info(cloner):
    """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’è¡¨ç¤º"""
    print("\n=== ã‚·ã‚¹ãƒ†ãƒ æƒ…å ± ===")
    print(f"Dataset path: {cloner.dataset_path}")
    print(f"Audio files path: {cloner.audio_path}")
    print(f"Text files path: {cloner.meta_path}")
    print(f"Models path: {cloner.models_path}")
    print(f"Output path: {cloner.output_path}")
    print(f"Device: {cloner.device}")
    
    # GPUæƒ…å ±ã‚’è¡¨ç¤º
    if cloner.device.type == 'cuda':
        try:
            import torch
            print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB")
            print(f"GPU Name: {torch.cuda.get_device_properties(0).name}")
        except:
            pass
    
    if hasattr(cloner.text_processor, 'vocab') and cloner.text_processor.vocab:
        print(f"Vocabulary size: {len(cloner.text_processor.vocab)}")
    else:
        print("Vocabulary: Not built yet")
    
    if cloner.model is not None:
        print("Model: Loaded")
        # ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’è¡¨ç¤º
        try:
            total_params = sum(p.numel() for p in cloner.model.parameters())
            print(f"Model parameters: {total_params:,}")
        except:
            pass
    else:
        print("Model: Not loaded")

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼1: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‰å‡¦ç†ã¨ãƒ¢ãƒ‡ãƒ«è¨“ç·´
# =============================================================================

def train_model_interactive(cloner):
    """å¯¾è©±å¼ã§ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚’å®Ÿè¡Œ"""
    print("ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚’é–‹å§‹ã—ã¾ã™...")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    audio_files, text_files = cloner.collect_data_files()
    if len(audio_files) == 0:
        print("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        print("å…ˆã«ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚")
        return
    
    print(f"âœ“ {len(audio_files)}å€‹ã®ãƒ‡ãƒ¼ã‚¿ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å…¥åŠ›
    try:
        epochs_input = input("ã‚¨ãƒãƒƒã‚¯æ•°ã‚’å…¥åŠ› (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100): ").strip()
        epochs = int(epochs_input) if epochs_input else 100
        
        if epochs <= 0:
            print("ã‚¨ãƒãƒƒã‚¯æ•°ã¯1ä»¥ä¸Šã§å…¥åŠ›ã—ã¦ãã ã•ã„")
            return
            
        batch_size_input = input("ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å…¥åŠ› (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2): ").strip()
        batch_size = int(batch_size_input) if batch_size_input else 2
        
        if batch_size <= 0 or batch_size > len(audio_files):
            print(f"ãƒãƒƒãƒã‚µã‚¤ã‚ºã¯1ä»¥ä¸Š{len(audio_files)}ä»¥ä¸‹ã§å…¥åŠ›ã—ã¦ãã ã•ã„")
            return
        
        learning_rate_input = input("å­¦ç¿’ç‡ã‚’å…¥åŠ› (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.001): ").strip()
        learning_rate = float(learning_rate_input) if learning_rate_input else 0.001
        
        print(f"\nè¨“ç·´è¨­å®š:")
        print(f"  ã‚¨ãƒãƒƒã‚¯æ•°: {epochs}")
        print(f"  ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}")
        print(f"  å­¦ç¿’ç‡: {learning_rate}")
        print(f"  ãƒ‡ãƒ¼ã‚¿æ•°: {len(audio_files)}")
        
        confirm = input("\nè¨“ç·´ã‚’é–‹å§‹ã—ã¾ã™ã‹ï¼Ÿ (y/N): ").strip().lower()
        if confirm != 'y':
            print("è¨“ç·´ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            return
        
        # è¨“ç·´å®Ÿè¡Œ
        cloner.train_model(epochs=epochs, batch_size=batch_size, learning_rate=learning_rate)
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        save_confirm = input("ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã™ã‹ï¼Ÿ (Y/n): ").strip().lower()
        if save_confirm != 'n':
            cloner.save_model()
            print("âœ“ ãƒ¢ãƒ‡ãƒ«ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ")
        
    except ValueError as e:
        print(f"âŒ å…¥åŠ›å€¤ã‚¨ãƒ©ãƒ¼: {e}")
    except Exception as e:
        print(f"âŒ è¨“ç·´ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        traceback.print_exc()

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼2: æ—¢å­˜ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
# =============================================================================

def load_model_interactive(cloner):
    """å¯¾è©±å¼ã§ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚’å®Ÿè¡Œ"""
    model_path = input("èª­ã¿è¾¼ã‚€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ã‚’å…¥åŠ› (ç©ºç™½ã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ): ").strip()
    if not model_path:
        model_path = None
    cloner.load_model(model_path)

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼3: éŸ³å£°åˆæˆ
# =============================================================================

def synthesize_speech_interactive(cloner):
    """å¯¾è©±å¼ã§éŸ³å£°åˆæˆã‚’å®Ÿè¡Œ"""
    if cloner.model is None:
        print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        print("å…ˆã«ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã‹è¨“ç·´ã—ã¦ãã ã•ã„ã€‚")
        return
    
    try:
        text = input("åˆæˆã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›: ").strip()
        if not text:
            print("âŒ ãƒ†ã‚­ã‚¹ãƒˆãŒå…¥åŠ›ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
            return
        
        output_path = input("å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆç©ºç™½ã§defaultï¼‰: ").strip()
        if not output_path:
            output_path = None
        
        print(f"éŸ³å£°åˆæˆä¸­: '{text}'")
        cloner.synthesize_speech(text, output_path)
        
    except Exception as e:
        print(f"âŒ éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼4: æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ ï¼ˆæœªå®Ÿè£…ï¼‰
# =============================================================================

def add_new_data_interactive(cloner):
    """æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ ï¼ˆä»Šå¾Œå®Ÿè£…äºˆå®šï¼‰"""
    print("ã“ã®æ©Ÿèƒ½ã¯ä»Šå¾Œå®Ÿè£…äºˆå®šã§ã™ã€‚")

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼5: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
# =============================================================================

def display_data_files(cloner):
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º"""
    audio_files, text_files = cloner.collect_data_files()
    print("\n=== æ¤œå‡ºã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« ===")
    
    if len(audio_files) == 0:
        print("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        print("\næ­£ã—ã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ :")
        print("dataset/")
        print("â”œâ”€â”€ audio_files/")
        print("â”‚   â”œâ”€â”€ audio_1.wav")
        print("â”‚   â”œâ”€â”€ audio_2.wav")
        print("â”‚   â””â”€â”€ ...")
        print("â””â”€â”€ meta_files/")
        print("    â”œâ”€â”€ meta_1.txt")
        print("    â”œâ”€â”€ meta_2.txt")
        print("    â””â”€â”€ ...")
        
        print("\nâ— ãƒ•ã‚¡ã‚¤ãƒ«åã¯å¿…ãš 'audio_N.wav' ã¨ 'meta_N.txt' ã®å½¢å¼ã§ã€")
        print("   Nã¯åŒã˜ç•ªå·ã«ã—ã¦ãã ã•ã„ã€‚")
    else:
        print(f"âœ“ {len(audio_files)}å€‹ã®ãƒ‡ãƒ¼ã‚¿ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:\n")
        for i, (audio, text) in enumerate(zip(audio_files, text_files)):
            print(f"{i+1:2d}. Audio: {os.path.basename(audio)}")
            print(f"     Text:  {os.path.basename(text)}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚‚è¡¨ç¤º
            try:
                audio_size = os.path.getsize(audio) / 1024  # KB
                print(f"     Size:  {audio_size:.1f} KB")
            except:
                print(f"     Size:  ä¸æ˜")
            print()

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼6: ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±è¡¨ç¤ºï¼ˆä¸Šè¨˜ã§å®šç¾©æ¸ˆã¿ï¼‰
# =============================================================================

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼7: å‰å‡¦ç†çµæœç¢ºèª
# =============================================================================

def display_preprocessing_results(cloner):
    """å‰å‡¦ç†çµæœã‚’è¡¨ç¤º"""
    processed_audio_dir = os.path.join(cloner.processed_path, "cleaned_audio")
    comparison_dir = os.path.join(cloner.processed_path, "comparison")
    audio_comparison_dir = os.path.join(comparison_dir, "audio_pairs")
    stages_dir = os.path.join(comparison_dir, "processing_stages")
    stats_file = os.path.join(cloner.processed_path, "preprocessing_stats.json")
    
    print("\n=== å‰å‡¦ç†çµæœ ===")
    
    # çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    if os.path.exists(stats_file):
        try:
            import json
            with open(stats_file, 'r', encoding='utf-8') as f:
                stats = json.load(f)
            
            summary = stats["processing_summary"]
            print(f"å‡¦ç†æ—¥æ™‚: {summary['timestamp']}")
            print(f"ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {summary['total_files']}")
            print(f"å‡¦ç†æˆåŠŸ: {summary['processed_files']}")
            print(f"æˆåŠŸç‡: {summary['success_rate']:.1f}%")
            
            # è©³ç´°è¡¨ç¤º
            if input("\nè©³ç´°ã‚’è¡¨ç¤ºã—ã¾ã™ã‹ï¼Ÿ (y/N): ").strip().lower() == 'y':
                print("\n=== ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥è©³ç´° ===")
                for detail in stats["file_details"]:
                    if "error" not in detail:
                        print(f"\n{detail['index']:2d}. {detail['original_file']}")
                        print(f"     ã‚µã‚¤ã‚º: {detail['original_size_kb']:.1f}KB â†’ {detail['processed_size_kb']:.1f}KB ({detail['size_reduction_percent']:+.1f}%)")
                        print(f"     é•·ã•:   {detail['original_duration_sec']:.2f}s â†’ {detail['processed_duration_sec']:.2f}s ({detail['duration_reduction_percent']:+.1f}%)")
                    else:
                        print(f"\n{detail['index']:2d}. {detail['original_file']} - {detail['error']}")
        
        except Exception as e:
            print(f"âŒ çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        print("âŒ å‰å‡¦ç†çµ±è¨ˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæƒ…å ±
    print(f"\n=== ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ« ===")
    
    # å‰å‡¦ç†æ¸ˆã¿éŸ³å£°
    if os.path.exists(processed_audio_dir):
        processed_files = [f for f in os.listdir(processed_audio_dir) if f.endswith('.wav')]
        print(f"ğŸ“ å‰å‡¦ç†æ¸ˆã¿éŸ³å£°: {len(processed_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        print(f"   å ´æ‰€: {processed_audio_dir}")
    else:
        print("âŒ å‰å‡¦ç†æ¸ˆã¿éŸ³å£°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # æ¯”è¼ƒç”¨éŸ³å£°ãƒšã‚¢
    if os.path.exists(audio_comparison_dir):
        comparison_files = [f for f in os.listdir(audio_comparison_dir) if f.endswith('.wav')]
        original_files = [f for f in comparison_files if f.startswith('original_')]
        processed_files = [f for f in comparison_files if f.startswith('processed_')]
        print(f"ğŸ“ æ¯”è¼ƒç”¨éŸ³å£°ãƒšã‚¢: {len(original_files)}çµ„")
        print(f"   å ´æ‰€: {audio_comparison_dir}")
    else:
        print("âŒ æ¯”è¼ƒç”¨éŸ³å£°ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # å‡¦ç†æ®µéšåˆ¥éŸ³å£°
    if os.path.exists(stages_dir):
        stage_files = [f for f in os.listdir(stages_dir) if f.endswith('.wav')]
        print(f"ğŸ“ å‡¦ç†æ®µéšåˆ¥éŸ³å£°: {len(stage_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        print(f"   å ´æ‰€: {stages_dir}")
    else:
        print("âŒ å‡¦ç†æ®µéšåˆ¥éŸ³å£°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # æ¯”è¼ƒç”»åƒ
    if os.path.exists(comparison_dir):
        comparison_images = [f for f in os.listdir(comparison_dir) if f.endswith('.png')]
        print(f"ğŸ“ æ¯”è¼ƒç”»åƒ: {len(comparison_images)}ãƒ•ã‚¡ã‚¤ãƒ«")
        print(f"   å ´æ‰€: {comparison_dir}")
    else:
        print("âŒ æ¯”è¼ƒç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼8: ãƒ¢ãƒ‡ãƒ«ãƒ»éŸ³å£°åˆæˆè¨ºæ–­
# =============================================================================

def check_model_status(cloner):
    """ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°çŠ¶æ…‹ã‚’ç¢ºèª"""
    print("=== ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ç¢ºèª ===")
    
    # 1. ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    model_path = os.path.join(cloner.models_path, "voice_clone_model.pth")
    print(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: {model_path}")
    print(f"å­˜åœ¨: {os.path.exists(model_path)}")
    
    if os.path.exists(model_path):
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
            file_size = os.path.getsize(model_path) / (1024 * 1024)  # MB
            print(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:.2f} MB")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®ç°¡æ˜“ç¢ºèª
            import torch
            checkpoint = torch.load(model_path, map_location='cpu')
            print(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚­ãƒ¼: {list(checkpoint.keys())}")
            
            if 'model_state_dict' in checkpoint:
                print("âœ“ model_state_dict ãŒå­˜åœ¨")
            else:
                print("âŒ model_state_dict ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
            if 'text_processor' in checkpoint:
                print("âœ“ text_processor ãŒå­˜åœ¨")
                
                # èªå½™ã®ç¢ºèª
                text_proc = checkpoint['text_processor']
                if hasattr(text_proc, 'vocab') and text_proc.vocab:
                    vocab = text_proc.vocab
                    print(f"âœ“ èªå½™ã‚µã‚¤ã‚º: {len(vocab)}")
                    
                    # èªå½™ã®å‹ã‚’ç¢ºèªã—ã¦é©åˆ‡ã«è¡¨ç¤º
                    if isinstance(vocab, dict):
                        print(f"èªå½™ã‚µãƒ³ãƒ—ãƒ«: {list(vocab.keys())[:10]}")
                        print("èªå½™å‹: è¾æ›¸")
                    elif isinstance(vocab, set):
                        print(f"èªå½™ã‚µãƒ³ãƒ—ãƒ«: {list(vocab)[:10]}")
                        print("èªå½™å‹: ã‚»ãƒƒãƒˆ")
                    elif isinstance(vocab, list):
                        print(f"èªå½™ã‚µãƒ³ãƒ—ãƒ«: {vocab[:10]}")
                        print("èªå½™å‹: ãƒªã‚¹ãƒˆ")
                    else:
                        print(f"èªå½™å‹: {type(vocab)}")
                else:
                    print("âŒ èªå½™ãŒç©ºã¾ãŸã¯å­˜åœ¨ã—ã¾ã›ã‚“")
            else:
                print("âŒ text_processor ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    # 2. ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹
    print(f"\nç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«: {cloner.model}")
    print(f"ç¾åœ¨ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ã‚»ãƒƒã‚µ: {cloner.text_processor}")
    
    if hasattr(cloner.text_processor, 'vocab') and cloner.text_processor.vocab:
        vocab = cloner.text_processor.vocab
        print(f"ç¾åœ¨ã®èªå½™: {len(vocab)}å€‹")
        print(f"ç¾åœ¨ã®èªå½™å‹: {type(vocab)}")
    else:
        print("âŒ ç¾åœ¨ã®èªå½™ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

def diagnose_model_and_synthesis(cloner):
    """ãƒ¢ãƒ‡ãƒ«ã¨éŸ³å£°åˆæˆã®è¨ºæ–­"""
    print("=== ãƒ¢ãƒ‡ãƒ«è¨ºæ–­ ===")
    
    if cloner.model is None:
        print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    # 1. ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹ç¢ºèª
    print("âœ“ ãƒ¢ãƒ‡ãƒ«ã¯èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã™")
    
    # 2. èªå½™ã‚µã‚¤ã‚ºç¢ºèª
    if hasattr(cloner.text_processor, 'vocab') and cloner.text_processor.vocab:
        vocab = cloner.text_processor.vocab
        vocab_size = len(vocab)
        print(f"èªå½™ã‚µã‚¤ã‚º: {vocab_size}")
        
        # èªå½™ã®å‹ã«å¿œã˜ã¦è¡¨ç¤º
        if isinstance(vocab, dict):
            print(f"ã‚µãƒ³ãƒ—ãƒ«èªå½™: {list(vocab.keys())[:10]}")
            print("èªå½™å½¢å¼: æ–‡å­—â†’IDè¾æ›¸")
        elif isinstance(vocab, set):
            vocab_list = list(vocab)
            print(f"ã‚µãƒ³ãƒ—ãƒ«èªå½™: {vocab_list[:10]}")
            print("èªå½™å½¢å¼: æ–‡å­—ã‚»ãƒƒãƒˆ")
            print("âš ï¸  èªå½™ãŒã‚»ãƒƒãƒˆå½¢å¼ã§ã™ã€‚è¾æ›¸å½¢å¼ã«å¤‰æ›ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“")
            try:
                test_dict = {char: i for i, char in enumerate(sorted(vocab))}
                print(f"å¤‰æ›ãƒ†ã‚¹ãƒˆæˆåŠŸ: {list(test_dict.items())[:5]}")
            except Exception as e:
                print(f"å¤‰æ›ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        elif isinstance(vocab, list):
            print(f"ã‚µãƒ³ãƒ—ãƒ«èªå½™: {vocab[:10]}")
            print("èªå½™å½¢å¼: æ–‡å­—ãƒªã‚¹ãƒˆ")
        else:
            print(f"èªå½™å½¢å¼: {type(vocab)}")
    else:
        print("âŒ èªå½™ãŒæ§‹ç¯‰ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    # 3. ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç¢ºèª
    try:
        total_params = sum(p.numel() for p in cloner.model.parameters())
        trainable_params = sum(p.numel() for p in cloner.model.parameters() if p.requires_grad)
        print(f"ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
        print(f"å­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {trainable_params:,}")
    except Exception as e:
        print(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
    
    # 4. ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ãƒ†ã‚¹ãƒˆ
    print("\n=== å‡ºåŠ›ãƒ†ã‚¹ãƒˆ ===")
    test_text = "ãƒ†ã‚¹ãƒˆ"
    
    try:
        import torch
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’æ•°å€¤ã«å¤‰æ›
        text_sequence = cloner.text_processor.text_to_sequence(test_text)
        text_tensor = torch.LongTensor(text_sequence).unsqueeze(0).to(cloner.device)
        text_lengths = torch.LongTensor([len(text_sequence)]).to(cloner.device)
        
        print(f"å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ: '{test_text}'")
        print(f"å¤‰æ›å¾Œæ•°å€¤: {text_sequence}")
        print(f"ãƒ†ãƒ³ã‚½ãƒ«ã‚µã‚¤ã‚º: {text_tensor.shape}")
        
        # å¤‰æ›çµæœã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        if all(x == 0 for x in text_sequence):
            print("âŒ è­¦å‘Š: å…¨ã¦0ã«å¤‰æ›ã•ã‚Œã¦ã„ã¾ã™ï¼ˆèªå½™ã®å•é¡Œã®å¯èƒ½æ€§ï¼‰")
        elif max(text_sequence) >= len(cloner.text_processor.vocab):
            print(f"âŒ è­¦å‘Š: èªå½™ã‚µã‚¤ã‚º({len(cloner.text_processor.vocab)})ã‚’è¶…ãˆã‚‹IDãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
        else:
            print("âœ“ ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ã¯æ­£å¸¸ã«è¦‹ãˆã¾ã™")
        
        # ãƒ¢ãƒ‡ãƒ«æ¨è«–
        cloner.model.eval()
        with torch.no_grad():
            mel_outputs, stop_outputs = cloner.model(text_tensor, text_lengths)
        
        print(f"ãƒ¡ãƒ«å‡ºåŠ›ã‚µã‚¤ã‚º: {mel_outputs.shape}")
        print(f"ãƒ¡ãƒ«å‡ºåŠ›ã®ç¯„å›²: [{mel_outputs.min().item():.3f}, {mel_outputs.max().item():.3f}]")
        print(f"ãƒ¡ãƒ«å‡ºåŠ›ã®å¹³å‡: {mel_outputs.mean().item():.3f}")
        print(f"åœæ­¢ãƒˆãƒ¼ã‚¯ãƒ³: {stop_outputs.mean().item():.3f}")
        
        # å‡ºåŠ›ã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯
        if torch.all(mel_outputs == 0):
            print("âŒ ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ å‡ºåŠ›ãŒå…¨ã¦0ã§ã™")
        elif mel_outputs.std() < 0.01:
            print("âŒ ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ å‡ºåŠ›ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
        else:
            print("âœ“ ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ å‡ºåŠ›ã¯æ­£å¸¸ã«è¦‹ãˆã¾ã™")
        
    except Exception as e:
        print(f"âŒ å‡ºåŠ›ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()

def diagnose_synthesis_process(cloner, text="ã“ã‚“ã«ã¡ã¯"):
    """éŸ³å£°åˆæˆãƒ—ãƒ­ã‚»ã‚¹ã®è©³ç´°è¨ºæ–­"""
    print(f"\n=== éŸ³å£°åˆæˆãƒ—ãƒ­ã‚»ã‚¹è¨ºæ–­ ===")
    print(f"åˆæˆãƒ†ã‚­ã‚¹ãƒˆ: '{text}'")
    
    try:
        import torch
        import numpy as np
        
        # Step 1: ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†
        text_sequence = cloner.text_processor.text_to_sequence(text)
        text_tensor = torch.LongTensor(text_sequence).unsqueeze(0).to(cloner.device)
        text_lengths = torch.LongTensor([len(text_sequence)]).to(cloner.device)
        
        print(f"âœ“ ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†å®Œäº†: {text_sequence}")
        
        # Step 2: ãƒ¢ãƒ‡ãƒ«æ¨è«–
        cloner.model.eval()
        with torch.no_grad():
            mel_outputs, stop_outputs = cloner.model(text_tensor, text_lengths)
        
        mel_spec = mel_outputs.squeeze(0).cpu()
        print(f"âœ“ ãƒ¢ãƒ‡ãƒ«æ¨è«–å®Œäº†: {mel_spec.shape}")
        print(f"  ãƒ¡ãƒ«ç¯„å›²: [{mel_spec.min():.3f}, {mel_spec.max():.3f}]")
        print(f"  ãƒ¡ãƒ«å¹³å‡: {mel_spec.mean():.3f}")
        print(f"  ãƒ¡ãƒ«æ¨™æº–åå·®: {mel_spec.std():.3f}")
        
        # Step 3: ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ãƒ†ã‚¹ãƒˆ
        print(f"\nå„ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ã®ãƒ†ã‚¹ãƒˆ:")
        
        # Griffin-Lim
        try:
            audio_griffin = cloner._griffin_lim_synthesis(mel_spec)
            print(f"âœ“ Griffin-Lim: {len(audio_griffin)} samples")
            print(f"  éŸ³å£°ç¯„å›²: [{audio_griffin.min():.6f}, {audio_griffin.max():.6f}]")
            print(f"  éŸ³å£°RMS: {torch.sqrt(torch.mean(audio_griffin**2)):.6f}")
        except Exception as e:
            print(f"âŒ Griffin-Lim ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ç°¡æ˜“ãƒœã‚³ãƒ¼ãƒ€ãƒ¼
        try:
            audio_simple = cloner._simple_vocoder(mel_spec)
            print(f"âœ“ ç°¡æ˜“ãƒœã‚³ãƒ¼ãƒ€ãƒ¼: {len(audio_simple)} samples")
            print(f"  éŸ³å£°ç¯„å›²: [{audio_simple.min():.6f}, {audio_simple.max():.6f}]")
            print(f"  éŸ³å£°RMS: {torch.sqrt(torch.mean(audio_simple**2)):.6f}")
        except Exception as e:
            print(f"âŒ ç°¡æ˜“ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ ã‚¨ãƒ©ãƒ¼: {e}")
        
        # æ”¹å–„ãƒœã‚³ãƒ¼ãƒ€ãƒ¼
        if hasattr(cloner, '_improved_vocoder'):
            try:
                audio_improved = cloner._improved_vocoder(mel_spec)
                print(f"âœ“ æ”¹å–„ãƒœã‚³ãƒ¼ãƒ€ãƒ¼: {len(audio_improved)} samples")
                print(f"  éŸ³å£°ç¯„å›²: [{audio_improved.min():.6f}, {audio_improved.max():.6f}]")
                print(f"  éŸ³å£°RMS: {torch.sqrt(torch.mean(audio_improved**2)):.6f}")
            except Exception as e:
                print(f"âŒ æ”¹å–„ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ ã‚¨ãƒ©ãƒ¼: {e}")
            
    except Exception as e:
        print(f"âŒ è¨ºæ–­ã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()

def force_load_model(cloner):
    """å¼·åˆ¶çš„ã«ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ç›´ã™"""
    print("=== å¼·åˆ¶ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ ===")
    
    model_path = os.path.join(cloner.models_path, "voice_clone_model.pth")
    
    if not os.path.exists(model_path):
        print("âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        print("å…ˆã«ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¦ãã ã•ã„ï¼ˆãƒ¡ãƒ‹ãƒ¥ãƒ¼1ï¼‰")
        return False
    
    try:
        print("ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        cloner.load_model(model_path)
        
        if cloner.model is not None:
            print("âœ“ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
            
            if hasattr(cloner.text_processor, 'vocab') and cloner.text_processor.vocab:
                print(f"âœ“ èªå½™èª­ã¿è¾¼ã¿æˆåŠŸ: {len(cloner.text_processor.vocab)}å€‹")
                
                test_text = "ã“ã‚“ã«ã¡ã¯"
                test_sequence = cloner.text_processor.text_to_sequence(test_text)
                print(f"ãƒ†ã‚¹ãƒˆå¤‰æ›: '{test_text}' â†’ {test_sequence}")
                
                if all(x == 0 for x in test_sequence):
                    print("âŒ ã¾ã ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ãŒæ­£å¸¸ã§ã¯ã‚ã‚Šã¾ã›ã‚“")
                    return False
                else:
                    print("âœ“ ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›æ­£å¸¸")
                    return True
            else:
                print("âŒ èªå½™ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                return False
        else:
            print("âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—")
            return False
            
    except Exception as e:
        print(f"âŒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
        return False

def verify_training_data_and_retrain(cloner):
    """è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦å¿…è¦ã«å¿œã˜ã¦å†è¨“ç·´"""
    print("=== è¨“ç·´ãƒ‡ãƒ¼ã‚¿ç¢ºèª ===")
    
    audio_files, text_files = cloner.collect_data_files()
    print(f"ãƒ‡ãƒ¼ã‚¿ãƒšã‚¢æ•°: {len(audio_files)}")
    
    if len(audio_files) == 0:
        print("âŒ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return False
    
    # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ç¢ºèª
    print("\nãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µãƒ³ãƒ—ãƒ«:")
    for i in range(min(3, len(text_files))):
        try:
            with open(text_files[i], 'r', encoding='utf-8') as f:
                content = f.read().strip()
            print(f"  {i+1}. {os.path.basename(text_files[i])}: '{content[:30]}{'...' if len(content) > 30 else ''}'")
        except Exception as e:
            print(f"  {i+1}. {os.path.basename(text_files[i])}: ã‚¨ãƒ©ãƒ¼ - {e}")
    
    # å†è¨“ç·´ã®ææ¡ˆ
    retrain = input(f"\n{len(audio_files)}å€‹ã®ãƒ‡ãƒ¼ã‚¿ã§å†è¨“ç·´ã—ã¾ã™ã‹ï¼Ÿ (y/N): ").strip().lower()
    if retrain == 'y':
        print("å†è¨“ç·´ã‚’é–‹å§‹...")
        
        try:
            cloner.train_model(epochs=10, batch_size=1, learning_rate=0.001)
            cloner.save_model()
            print("âœ“ å†è¨“ç·´å®Œäº†")
            return True
        except Exception as e:
            print(f"âŒ å†è¨“ç·´ã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
            return False
    
    return False

def model_synthesis_diagnosis_menu(cloner):
    """ãƒ¡ãƒ‹ãƒ¥ãƒ¼8: ãƒ¢ãƒ‡ãƒ«ãƒ»éŸ³å£°åˆæˆè¨ºæ–­ã®çµ±åˆãƒ¡ãƒ‹ãƒ¥ãƒ¼"""
    # ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ç¢ºèª
    check_model_status(cloner)
    
    # ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ãªã„å ´åˆã®å¯¾å¿œ
    if cloner.model is None:
        print("\n=== ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¯¾å¿œ ===")
        print("1. æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’å¼·åˆ¶èª­ã¿è¾¼ã¿")
        print("2. ãƒ‡ãƒ¼ã‚¿ç¢ºèªã¨å†è¨“ç·´")
        
        sub_choice = input("é¸æŠ (1/2): ").strip()
        
        if sub_choice == "1":
            if force_load_model(cloner):
                print("âœ“ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸã€è¨ºæ–­ã‚’ç¶šè¡Œ...")
                diagnose_model_and_synthesis(cloner)
                diagnose_synthesis_process(cloner)
            else:
                print("âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—")
        
        elif sub_choice == "2":
            if verify_training_data_and_retrain(cloner):
                print("âœ“ å†è¨“ç·´å®Œäº†ã€è¨ºæ–­ã‚’ç¶šè¡Œ...")
                diagnose_model_and_synthesis(cloner)
                diagnose_synthesis_process(cloner)
            else:
                print("âŒ å†è¨“ç·´å¤±æ•—")
    else:
        # ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯é€šå¸¸ã®è¨ºæ–­
        diagnose_model_and_synthesis(cloner)
        diagnose_synthesis_process(cloner)

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼9: ãƒ†ã‚¹ãƒˆéŸ³å£°ç”Ÿæˆ
# =============================================================================

def generate_test_audio(cloner):
    """ãƒ†ã‚¹ãƒˆç”¨éŸ³å£°ã‚’ç”Ÿæˆ"""
    print("\n=== ãƒ†ã‚¹ãƒˆéŸ³å£°ç”Ÿæˆ ===")
    
    import torch
    import torchaudio
    import numpy as np
    
    # 1. ç´”ç²‹ãªã‚µã‚¤ãƒ³æ³¢ãƒ†ã‚¹ãƒˆ
    print("1. ã‚µã‚¤ãƒ³æ³¢ãƒ†ã‚¹ãƒˆéŸ³å£°ã‚’ç”Ÿæˆ...")
    sample_rate = cloner.preprocessor.sample_rate
    duration = 2.0  # 2ç§’
    frequency = 440  # A4
    
    t = torch.linspace(0, duration, int(sample_rate * duration))
    sine_wave = 0.3 * torch.sin(2 * 3.14159 * frequency * t)
    
    test_path = os.path.join(cloner.output_path, "test_sine_wave.wav")
    torchaudio.save(test_path, sine_wave.unsqueeze(0), sample_rate)
    print(f"âœ“ ã‚µã‚¤ãƒ³æ³¢ä¿å­˜: {test_path}")
    
    # 2. ãƒ©ãƒ³ãƒ€ãƒ ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰ã®éŸ³å£°ç”Ÿæˆ
    print("2. ãƒ©ãƒ³ãƒ€ãƒ ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ãƒ†ã‚¹ãƒˆ...")
    
    mel_frames = 100
    mel_bins = 80
    random_mel = torch.randn(mel_frames, mel_bins) * 0.5
    
    try:
        random_audio = cloner._simple_vocoder(random_mel)
        test_path2 = os.path.join(cloner.output_path, "test_random_mel.wav")
        torchaudio.save(test_path2, random_audio.unsqueeze(0), sample_rate)
        print(f"âœ“ ãƒ©ãƒ³ãƒ€ãƒ ãƒ¡ãƒ«éŸ³å£°ä¿å­˜: {test_path2}")
        print(f"  éŸ³å£°é•·: {len(random_audio)/sample_rate:.2f}ç§’")
        print(f"  æœ€å¤§æŒ¯å¹…: {torch.max(torch.abs(random_audio)):.6f}")
    except Exception as e:
        print(f"âŒ ãƒ©ãƒ³ãƒ€ãƒ ãƒ¡ãƒ«ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    # 3. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®1ã‚µãƒ³ãƒ—ãƒ«ç¢ºèª
    print("3. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ç¢ºèª...")
    
    audio_files, text_files = cloner.collect_data_files()
    if len(audio_files) > 0:
        sample_audio = cloner.preprocessor.load_audio(audio_files[0])
        if len(sample_audio) > 0:
            print(f"âœ“ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«: {len(sample_audio)} samples")
            print(f"  æœ€å¤§æŒ¯å¹…: {np.max(np.abs(sample_audio)):.6f}")
            print(f"  RMS: {np.sqrt(np.mean(sample_audio**2)):.6f}")
            
            test_path3 = os.path.join(cloner.output_path, "test_training_sample.wav")
            torchaudio.save(test_path3, torch.from_numpy(sample_audio).unsqueeze(0), sample_rate)
            print(f"âœ“ å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«ä¿å­˜: {test_path3}")

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼10: è©³ç´°ãƒ¢ãƒ‡ãƒ«è¨ºæ–­
# =============================================================================

def detailed_model_diagnosis(cloner):
    """è©³ç´°ãªãƒ¢ãƒ‡ãƒ«è¨ºæ–­"""
    print("=== è©³ç´°ãƒ¢ãƒ‡ãƒ«è¨ºæ–­ ===")
    
    if cloner.model is None:
        print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    import torch
    import numpy as np
    
    # 1. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±
    audio_files, text_files = cloner.collect_data_files()
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {len(audio_files)}å€‹")
    
    # 2. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ã®ç¢ºèª
    print("\n=== è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ« ===")
    for i in range(min(3, len(text_files))):
        try:
            with open(text_files[i], 'r', encoding='utf-8') as f:
                text_content = f.read().strip()
            
            sequence = cloner.text_processor.text_to_sequence(text_content)
            print(f"{i+1}. ãƒ†ã‚­ã‚¹ãƒˆ: '{text_content[:50]}...'")
            print(f"   å¤‰æ›çµæœ: {sequence[:10]}... (é•·ã•: {len(sequence)})")
            
            import torchaudio
            waveform, sample_rate = torchaudio.load(audio_files[i])
            duration = waveform.shape[1] / sample_rate
            print(f"   éŸ³å£°é•·: {duration:.2f}ç§’, ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: {sample_rate}Hz")
            
        except Exception as e:
            print(f"{i+1}. ã‚¨ãƒ©ãƒ¼: {e}")
    
    # 3. ãƒ¢ãƒ‡ãƒ«ã®å„å±¤ã®å‡ºåŠ›ç¢ºèª
    print("\n=== ãƒ¢ãƒ‡ãƒ«å±¤åˆ¥å‡ºåŠ›ç¢ºèª ===")
    test_text = "ãƒ†ã‚¹ãƒˆ"
    test_sequence = cloner.text_processor.text_to_sequence(test_text)
    test_tensor = torch.LongTensor(test_sequence).unsqueeze(0).to(cloner.device)
    test_lengths = torch.LongTensor([len(test_sequence)]).to(cloner.device)
    
    cloner.model.eval()
    with torch.no_grad():
        # åŸ‹ã‚è¾¼ã¿å±¤ã®å‡ºåŠ›
        embedded = cloner.model.embedding(test_tensor)
        print(f"åŸ‹ã‚è¾¼ã¿å‡ºåŠ›: {embedded.shape}, ç¯„å›²: [{embedded.min():.3f}, {embedded.max():.3f}]")
        
        # LSTMå‡ºåŠ›
        lstm_out, _ = cloner.model.text_lstm(embedded)
        print(f"LSTMå‡ºåŠ›: {lstm_out.shape}, ç¯„å›²: [{lstm_out.min():.3f}, {lstm_out.max():.3f}]")
        
        # æœ€çµ‚å‡ºåŠ›
        mel_outputs, stop_outputs = cloner.model(test_tensor, test_lengths)
        print(f"ãƒ¡ãƒ«å‡ºåŠ›: {mel_outputs.shape}, ç¯„å›²: [{mel_outputs.min():.3f}, {mel_outputs.max():.3f}]")
        print(f"åœæ­¢å‡ºåŠ›: {stop_outputs.shape}, ç¯„å›²: [{stop_outputs.min():.3f}, {stop_outputs.max():.3f}]")
        
        # ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã®ç‰¹æ€§åˆ†æ
        mel_spec = mel_outputs.squeeze(0).cpu().numpy()
        print(f"\nãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ åˆ†æ:")
        print(f"  å¹³å‡: {np.mean(mel_spec):.3f}")
        print(f"  æ¨™æº–åå·®: {np.std(mel_spec):.3f}")
        print(f"  æœ€å°å€¤: {np.min(mel_spec):.3f}")
        print(f"  æœ€å¤§å€¤: {np.max(mel_spec):.3f}")
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥ã®å¤‰åŒ–
        frame_means = np.mean(mel_spec, axis=1)
        print(f"  ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã®å¤‰åŒ–: {np.std(frame_means):.3f}")
        if np.std(frame_means) < 0.1:
            print("  âš ï¸  ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã®å¤‰åŒ–ãŒå°‘ãªã™ãã¾ã™ï¼ˆå˜èª¿ãªå‡ºåŠ›ï¼‰")
        
        # å‘¨æ³¢æ•°åˆ¥ã®å¤‰åŒ–
        freq_means = np.mean(mel_spec, axis=0)
        print(f"  å‘¨æ³¢æ•°é–“ã®å¤‰åŒ–: {np.std(freq_means):.3f}")
        if np.std(freq_means) < 0.1:
            print("  âš ï¸  å‘¨æ³¢æ•°é–“ã®å¤‰åŒ–ãŒå°‘ãªã™ãã¾ã™ï¼ˆã‚¹ãƒšã‚¯ãƒˆãƒ«ç‰¹å¾´ä¸è¶³ï¼‰")

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼11: æ”¹å–„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å†è¨“ç·´
# =============================================================================

def retrain_with_better_parameters(cloner):
    """æ”¹å–„ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å†è¨“ç·´"""
    print("=== æ”¹å–„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®å†è¨“ç·´ ===")
    
    audio_files, text_files = cloner.collect_data_files()
    if len(audio_files) == 0:
        print("âŒ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    print(f"ãƒ‡ãƒ¼ã‚¿æ•°: {len(audio_files)}å€‹")
    
    # ã‚ˆã‚Šè‰¯ã„è¨“ç·´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    epochs = 100
    batch_size = 2
    learning_rate = 0.0005
    
    print(f"è¨“ç·´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
    print(f"  ã‚¨ãƒãƒƒã‚¯æ•°: {epochs}")
    print(f"  ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}")
    print(f"  å­¦ç¿’ç‡: {learning_rate}")
    
    confirm = input("ã“ã®è¨­å®šã§å†è¨“ç·´ã—ã¾ã™ã‹ï¼Ÿ (y/N): ").strip().lower()
    if confirm == 'y':
        try:
            cloner.train_model(
                epochs=epochs, 
                batch_size=batch_size, 
                learning_rate=learning_rate
            )
            cloner.save_model()
            print("âœ“ å†è¨“ç·´å®Œäº†")
            return True
        except Exception as e:
            print(f"âŒ å†è¨“ç·´ã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
            return False
    
    return False

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼12: ãƒœã‚³ãƒ¼ãƒ€ãƒ¼å•é¡Œè¨ºæ–­
# =============================================================================

def diagnose_vocoder_issue(cloner):
    """ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ã®å•é¡Œã‚’è©³ç´°è¨ºæ–­"""
    print("=== ãƒœã‚³ãƒ¼ãƒ€ãƒ¼å•é¡Œè¨ºæ–­ ===")
    
    if cloner.model is None:
        print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    import torch
    import numpy as np
    import torchaudio
    import os
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ç”Ÿæˆ
    test_text = "ã‚ã„ã†ãˆãŠ"
    test_sequence = cloner.text_processor.text_to_sequence(test_text)
    test_tensor = torch.LongTensor(test_sequence).unsqueeze(0).to(cloner.device)
    test_lengths = torch.LongTensor([len(test_sequence)]).to(cloner.device)
    
    cloner.model.eval()
    with torch.no_grad():
        mel_outputs, _ = cloner.model(test_tensor, test_lengths)
    
    mel_spec = mel_outputs.squeeze(0).cpu()
    
    # äººå·¥çš„ãªç†æƒ³çš„ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã¨æ¯”è¼ƒ
    print("äººå·¥ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã§ãƒ†ã‚¹ãƒˆ:")
    
    # ç°¡å˜ãªæ­£å¼¦æ³¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½œæˆ
    artificial_mel = np.zeros((50, 80))
    for i in range(50):
        for j in range(80):
            # ä½åŸŸã«å¼·ã„ä¿¡å·ã‚’é…ç½®
            if j < 20:
                artificial_mel[i, j] = -10 + 5 * np.sin(2 * np.pi * i / 10)
            elif j < 40:
                artificial_mel[i, j] = -20 + 3 * np.sin(2 * np.pi * i / 15)
            else:
                artificial_mel[i, j] = -30 + np.sin(2 * np.pi * i / 20)
    
    artificial_mel_tensor = torch.from_numpy(artificial_mel.astype(np.float32))
    
    # äººå·¥ãƒ¡ãƒ«ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã§ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ãƒ†ã‚¹ãƒˆ
    try:
        artificial_audio = cloner._improved_vocoder(artificial_mel_tensor)
        print(f"âœ“ äººå·¥ãƒ¡ãƒ« â†’ éŸ³å£°å¤‰æ›æˆåŠŸ: {len(artificial_audio)} samples")
        print(f"  éŸ³å£°ç¯„å›²: [{artificial_audio.min():.3f}, {artificial_audio.max():.3f}]")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¦ç¢ºèª
        test_path = os.path.join(cloner.output_path, "test_artificial.wav")
        torchaudio.save(test_path, artificial_audio.unsqueeze(0), cloner.preprocessor.sample_rate)
        print(f"âœ“ ãƒ†ã‚¹ãƒˆéŸ³å£°ä¿å­˜: {test_path}")
        
    except Exception as e:
        print(f"âŒ äººå·¥ãƒ¡ãƒ«ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    # å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã§ãƒ†ã‚¹ãƒˆ
    try:
        model_audio = cloner._improved_vocoder(mel_spec)
        print(f"ãƒ¢ãƒ‡ãƒ«å‡ºåŠ› â†’ éŸ³å£°å¤‰æ›: {len(model_audio)} samples")
        print(f"  éŸ³å£°ç¯„å›²: [{model_audio.min():.3f}, {model_audio.max():.3f}]")
        
        # å®Ÿéš›ã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ã®æ¯”è¼ƒ
        audio_files, _ = cloner.collect_data_files()
        if len(audio_files) > 0:
            original_audio, _ = torchaudio.load(audio_files[0])
            print(f"å…ƒéŸ³å£°ç¯„å›²: [{original_audio.min():.3f}, {original_audio.max():.3f}]")
            
    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼13: ç·Šæ€¥ãƒ¢ãƒ‡ãƒ«ä¿®æ­£ï¼ˆæ–°è¦è¿½åŠ ï¼‰
# =============================================================================

def emergency_model_fix(cloner):
    """ç·Šæ€¥ãƒ¢ãƒ‡ãƒ«ä¿®æ­£"""
    print("=== ç·Šæ€¥ãƒ¢ãƒ‡ãƒ«ä¿®æ­£ ===")
    
    if cloner.model is None:
        print("âŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        return False
    
    import torch
    
    # ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›é•·åˆ¶å¾¡ã‚’å¼·åˆ¶ä¿®æ­£
    original_forward = cloner.model.forward
    
    def fixed_forward(text_input, text_lengths, target_audio=None):
        # å…ƒã®å‡ºåŠ›ã‚’å–å¾—
        mel_outputs, stop_outputs = original_forward(text_input, text_lengths, target_audio)
        
        # å‡ºåŠ›ãŒçŸ­ã™ãã‚‹å ´åˆã¯å¼·åˆ¶å»¶é•·
        if mel_outputs.shape[1] < 20:  # 20ãƒ•ãƒ¬ãƒ¼ãƒ æœªæº€ã®å ´åˆ
            print(f"âš ï¸  å‡ºåŠ›ã‚’å¼·åˆ¶å»¶é•·: {mel_outputs.shape[1]} â†’ 50ãƒ•ãƒ¬ãƒ¼ãƒ ")
            
            # æœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç¹°ã‚Šè¿”ã—ã¦å»¶é•·
            last_frame = mel_outputs[:, -1:, :]
            repeat_count = 50 - mel_outputs.shape[1]
            
            # ã‚ãšã‹ãªãƒã‚¤ã‚ºã‚’è¿½åŠ ã—ã¦è‡ªç„¶ã«ã™ã‚‹
            noise = torch.randn_like(last_frame.repeat(1, repeat_count, 1)) * 0.5
            extended_frames = last_frame.repeat(1, repeat_count, 1) + noise
            
            mel_outputs = torch.cat([mel_outputs, extended_frames], dim=1)
            
            # åœæ­¢ãƒˆãƒ¼ã‚¯ãƒ³ã‚‚å»¶é•·
            stop_extension = torch.zeros(stop_outputs.shape[0], repeat_count, 1).to(stop_outputs.device)
            stop_outputs = torch.cat([stop_outputs, stop_extension], dim=1)
        
        return mel_outputs, stop_outputs
    
    # ãƒ¢ãƒ‡ãƒ«ã® forward ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç½®ãæ›ãˆ
    cloner.model.forward = fixed_forward
    
    print("âœ“ ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›é•·åˆ¶å¾¡ã‚’ä¿®æ­£ã—ã¾ã—ãŸ")
    return True

# =============================================================================
# ãƒ¡ãƒ‹ãƒ¥ãƒ¼142: å¤–éƒ¨ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ä½¿ç”¨è¨­å®šï¼ˆæ–°è¦è¿½åŠ ï¼‰
# =============================================================================

def use_external_vocoder(cloner):
    """å¤–éƒ¨ã®é«˜å“è³ªãƒœã‚³ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ç”¨"""
    print("=== é«˜å“è³ªãƒœã‚³ãƒ¼ãƒ€ãƒ¼è¨­å®š ===")
    print("1. æ”¹å–„ã•ã‚ŒãŸè‡ªä½œãƒœã‚³ãƒ¼ãƒ€ãƒ¼")
    print("2. WaveGlowï¼ˆå¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼‰")
    print("3. HiFi-GANï¼ˆæœ€é«˜å“è³ªï¼‰")
    
    choice = input("é¸æŠ (1/2/3): ").strip()
    
    if choice == "1":
        # ä¸Šè¨˜ã®_neural_vocoderã‚’ä½¿ç”¨
        print("âœ“ æ”¹å–„ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ã‚’è¨­å®šã—ã¾ã—ãŸ")
        return True
    elif choice == "2":
        print("WaveGlowã®çµ±åˆã¯ä»Šå¾Œå®Ÿè£…äºˆå®šã§ã™")
        return False
    elif choice == "3":
        print("HiFi-GANã®çµ±åˆã¯ä»Šå¾Œå®Ÿè£…äºˆå®šã§ã™")
        return False
    
    return False


def use_pretrained_approach(cloner):
    """äº‹å‰è¨“ç·´æ¸ˆã¿ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ"""
    print("=== ç·Šæ€¥å¯¾å¿œãƒ¡ãƒ‹ãƒ¥ãƒ¼ ===")
    print("ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯å‡ºåŠ›é•·ã®å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚")
    print("ä»¥ä¸‹ã®é¸æŠè‚¢ãŒã‚ã‚Šã¾ã™:")
    print()
    print("1. ç·Šæ€¥ä¿®æ­£ç‰ˆã§ç¶™ç¶šï¼ˆå³åº§ã«ä½¿ç”¨å¯èƒ½ï¼‰")
    print("2. é•·æ™‚é–“å†è¨“ç·´ï¼ˆ1-2æ™‚é–“ã€æ ¹æœ¬è§£æ±ºï¼‰")
    print("3. æˆ»ã‚‹")
    
    choice = input("é¸æŠ (1/2/3): ").strip()
    
    if choice == "1":
        return emergency_model_fix(cloner)
    elif choice == "2":
        return retrain_with_better_parameters(cloner)
    elif choice == "3":
        return False
    
    return False



# =============================================================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =============================================================================

def main():
    print("éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã¸ã‚ˆã†ã“ã")
    
    # ã‚¯ãƒ­ãƒ¼ãƒ³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸåŒ–
    cloner = VoiceCloner()
    
    # ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
    if not check_dependencies():
        sys.exit(1)
    
    while True:
        # ãƒ¡ãƒ‹ãƒ¥ãƒ¼è¡¨ç¤º
        print("\n=== ãƒ¡ãƒ‹ãƒ¥ãƒ¼ ===")
        print("1. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å‰å‡¦ç†ã¨ãƒ¢ãƒ‡ãƒ«è¨“ç·´")
        print("2. æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿")
        print("3. éŸ³å£°åˆæˆ")
        print("4. æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ ")
        print("5. ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª")
        print("6. ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±è¡¨ç¤º")
        print("7. å‰å‡¦ç†çµæœç¢ºèª")
        print("8. ãƒ¢ãƒ‡ãƒ«ãƒ»éŸ³å£°åˆæˆè¨ºæ–­")
        print("9. ãƒ†ã‚¹ãƒˆéŸ³å£°ç”Ÿæˆ")
        print("10. è©³ç´°ãƒ¢ãƒ‡ãƒ«è¨ºæ–­")
        print("11. æ”¹å–„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å†è¨“ç·´")
        print("12. ãƒœã‚³ãƒ¼ãƒ€ãƒ¼å•é¡Œè¨ºæ–­")
        print("13. ç·Šæ€¥ãƒ¢ãƒ‡ãƒ«ä¿®æ­£")
        print("14. å¤–éƒ¨ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ä½¿ç”¨è¨­å®š")
        print("0. çµ‚äº†")
        
        choice = input("é¸æŠè‚¢ã‚’å…¥åŠ›: ").strip()
        
        if choice == "0":
            print("ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ‚äº†ã—ã¾ã™")
            break
        elif choice == "1":
            train_model_interactive(cloner)
        elif choice == "2":
            load_model_interactive(cloner)
        elif choice == "3":
            synthesize_speech_interactive(cloner)
        elif choice == "4":
            add_new_data_interactive(cloner)
        elif choice == "5":
            display_data_files(cloner)
        elif choice == "6":
            display_system_info(cloner)
        elif choice == "7":
            display_preprocessing_results(cloner)
        elif choice == "8":
            model_synthesis_diagnosis_menu(cloner)
        elif choice == "9":
            generate_test_audio(cloner)
        elif choice == "10":
            detailed_model_diagnosis(cloner)
        elif choice == "11":
            retrain_with_better_parameters(cloner)
        elif choice == "12":
            diagnose_vocoder_issue(cloner)
        elif choice == "13":
            use_pretrained_approach(cloner)
        elif choice == "14":
            use_external_vocoder(cloner)
        else:
            print("ç„¡åŠ¹ãªé¸æŠè‚¢ã§ã™ã€‚å†åº¦å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()